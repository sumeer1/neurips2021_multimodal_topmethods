functionality:
  name: submission_170825
  namespace: joint_embedding_methods

  # metadata for your method
  description: A description for your method.
  info:
    method_label: "RAE"
    submission_id: "170825"
    team_name: Living-Systems-Lab
    # project_url: https://github.com/foo/bar
    # publication_doi: 10.1101/0123.45.67.890123
    # publication_url: https://arxiv.org/abs/1234.56789

  authors:
    - name: Sumeer Khan
      email: sumeer.khan@kaust.edu.sa
      roles: [ author, maintainer ]
    - name: Robert Lehman
      email: robert.lehman@kaust.edu.sa 
      roles: [ author, maintainer ]
    - name: Xabier Martinez De Morentin
      email: xavier.martinez.demorentin@navarra.es 
      roles: [ author, maintainer ]
    - name: Aidyn Ubingazhibov
      email: aidyn.ubingazhibov@nu.edu.kz
      roles: [ author, maintainer ]
    - name: Minxing Pang
      email: minxing.pang@kaust.edu.sa 
      roles: [ author, maintainer ]

  # parameters
  arguments:
    # required inputs
    - name: "--input_mod1"
      type: "file"
      example: "dataset_mod1.h5ad"
      description: Modality 1 dataset.
      required: true
    - name: "--input_mod2"
      type: "file"
      example: "dataset_mod2.h5ad"
      description: Modality 2 dataset.
      required: true
    # required outputs
    - name: "--output"
      type: "file"
      direction: "output"
      example: "output.h5ad"
      description: Data for all cells in mod1 and mod2 embedded to â‰¤100 dimensions.
      required: true

  # files your script needs
  resources:
    - type: python_script
      path: script.py

# target platforms
platforms:
  - type: docker
    image: nvcr.io/nvidia/tensorflow:20.10-tf1-py3
    run_args: [ "--gpus all" ]
    setup:
      - type: python
        packages:
          - anndata
          - umap-learn
          - keras
          - matplotlib
          - scanpy
          - scipy
  - type: nextflow
    labels: [ vhighmem, vvhightime, vhighcpu, gpu ]
